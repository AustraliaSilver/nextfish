import os
import subprocess
import time

# --- C·∫§U H√åNH ---
REPO_URL = "https://github.com/AustraliaSilver/nextfish.git"
MODEL_URL = "https://storage.lczero.org/files/networks-contrib/BT4-1024x15x32h-swa-6147500-policytune-332.pb.gz"
ONNX_LIB_URL = "https://github.com/microsoft/onnxruntime/releases/download/v1.17.1/onnxruntime-linux-x64-1.17.1.tgz"
ARCH = "x86-64-avx2"

def run_cmd(cmd, desc):
    print(f"\n[üöÄ] {desc}...")
    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    for line in process.stdout:
        print(f"  {line.strip()}")
    process.wait()
    return process.returncode == 0

def main():
    start_time = time.time()
    working_dir = "/kaggle/working"
    os.chdir(working_dir)

    # 1. Chu·∫©n b·ªã ONNX Runtime
    if not os.path.exists("onnxruntime-linux-x64-1.17.1"):
        run_cmd(f"wget {ONNX_LIB_URL} -O onnx.tgz && tar -zxvf onnx.tgz", "T·∫£i ONNX Runtime")
    
    onnx_root = os.path.join(working_dir, "onnxruntime-linux-x64-1.17.1")
    onnx_inc, onnx_lib = os.path.join(onnx_root, "include"), os.path.join(onnx_root, "lib")

    # 2. T·∫£i & V√° l·ªói m√£ ngu·ªìn (Fix Makefile)
    repo_dir = os.path.join(working_dir, "nextfish")
    if os.path.exists(repo_dir): run_cmd(f"rm -rf {repo_dir}", "D·ªçn d·∫πp")
    run_cmd(f"git clone {REPO_URL} {repo_dir}", "T·∫£i m√£ ngu·ªìn")
    
    src_dir = os.path.join(repo_dir, "src")
    os.chdir(src_dir)
    
    # V√° Makefile tr·ª±c ti·∫øp ƒë·ªÉ link ONNX Runtime (Th√™m CUDA support)
    print("[üõ†Ô∏è] ƒêang v√° Makefile ƒë·ªÉ h·ªó tr·ª£ ONNX GPU...")
    patch_make = f"""
    sed -i 's|LDFLAGS = $(ENV_LDFLAGS) $(EXTRALDFLAGS)|LDFLAGS = $(ENV_LDFLAGS) $(EXTRALDFLAGS) -L{onnx_lib} -lonnxruntime -lpthread -ldl -lcudart -lcuda -Wl,-rpath,{onnx_lib}|' Makefile
    """
    run_cmd(patch_make, "V√° Makefile")

    # 3. X·ª≠ l√Ω Model
    os.chdir(repo_dir)
    run_cmd(f"wget {MODEL_URL} -O model_raw.pb.gz && gunzip -f model_raw.pb.gz", "Chu·∫©n b·ªã Model")
    pb_file = next((f for f in os.listdir(".") if f.endswith(".pb")), None)
    if pb_file:
        run_cmd("pip install tf2onnx onnxruntime-gpu", "C√†i converter & GPU Runtime")
        # Ch·∫°y convert tr√™n CPU (CUDA_VISIBLE_DEVICES="") ƒë·ªÉ tr√°nh l·ªói b·ªô nh·ªõ GPU
        # S·ª≠ d·ª•ng t√™n node chu·∫©n kh√¥ng c√≥ :0
        run_cmd(f"CUDA_VISIBLE_DEVICES='' python -m tf2onnx.convert --input {pb_file} --output model.onnx --inputs input:0 --outputs policy:0,value:0 --fold_const", "Convert Model")
    model_path = os.path.abspath("model.onnx")

    # 4. Bi√™n d·ªãch
    os.chdir(src_dir)
    # B√¢y gi·ªù LDFLAGS ƒë√£ ƒë∆∞·ª£c v√° trong file, ch·ªâ c·∫ßn truy·ªÅn CXXFLAGS
    make_flags = f"ARCH={ARCH} COMP=gcc CXXFLAGS='-I{onnx_inc}'"
    
    if run_cmd(f"make -j$(nproc) build {make_flags}", "Bi√™n d·ªãch Nextfish"):
        engine_path = os.path.abspath("stockfish")
        print("\n" + "="*60)
        print(f"‚úÖ TH√ÄNH C√îNG! Engine t·∫°i: {engine_path}")
        print(f"üìç Model t·∫°i: {model_path}")
        print("="*60)
    else:
        print("[‚ùå] Bi√™n d·ªãch th·∫•t b·∫°i. H√£y ki·ªÉm tra l·∫°i log build.")

if __name__ == "__main__":
    main()